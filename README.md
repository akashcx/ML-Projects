# ML Projects
ML Projects made using Numpy, Pandas, Matplotlib, Seaborn, Scikit-Learn, TensorFlow and PySpark.

# Project Steps
1. Checking data, Checking statistics (info, describe, head)
2. Checking for Duplicate values (duplicated)
3. Checking if data is labelled correctly, the data has few inconsistencies 
4. Checking if all rows are in desirable datatype – Datetime as a Datetime object, not a string
5. Drop unnecessary columns
6. Plotting graphs (pairplot, scatterplot, boxplot etc.) to find relationship among features
7. Plotting Heat map for Correlation
8. Feature selection based on correlation 
9. Encoding Categorical Data – Nominal, Ordinal, Dummy Variable Trap (Label Encoder, One Hot Encoder, get_dummies)
10. Checking for Outliers
11.	Checking if data is skewed 
12. Feature Scaling – Standardisation/Normalisation
13.	Dealing with missing data – Deleting or Filling (SimpleImputer, Pandas)
14.	Splitting into Training and Test set 
15.	K Cross Validation, Nested Cross Validation
16.	Regression – Linear, Ridge & Lasso Regression, Decision Tree, Random Forest, KNN, SVR
17.	Classification – Logistic Regression, Decision Tree, Random Forest, KNN, Naïve Bayes, SVM
18.	Clustering – K-means, Hierarchical, DBscan
19.	Dimensionality Reduction – PCA, LDA 
20.	Ensemble Learning Techniques – Bagging (Majority voting – Classification, Mean (Regression, Random Forest, KNN), Boosting (Gradient Boosting, XGBoost, AdaBoost)
21.	Neural Networks (NN) – ANN or MLP, CNN, RNN
22.	Natural Language Processing (NLP)
23.	AutoEncoders – Unsupervised Learning, Dimensionality Reduction, Noise Removal 
24.	General Adversarial Networks (GANs) – Unsupervised Learning, Generate New Data
25.	Early Stopping for NN (Callbacks)
26.	Scikit Learn Optimizers – GridSearchCV, RandomizedSearchCV 
27.	Scikit-optimize, bayes_opt 
28.	Metrics – Regression, Classification, Clustering 
29. Plots – Loss function, Predictions vs True Value
30.	Accuracy – Own code
31.	Pipelines 
